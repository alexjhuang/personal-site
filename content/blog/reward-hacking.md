---
slug: reward-hacking
title: Reward hacking
date: 2026-01-12
cover: https://images.unsplash.com/photo-1518770660439-4636190af475?auto=format&fit=crop&w=1600&q=80
tags:
  - ML Systems
  - Alignment
excerpt: A short exploration of the ways models optimize the wrong objectives.
---

Reward hacking happens when a system optimizes the literal objective rather than the intended one.
